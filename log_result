#!/usr/bin/python

import os
import sys
import pdb
import subprocess
import redis
import re
import time
import argparse

os.environ['NO_PROXY'] = 'sap.corp,localhost,127.0.0.1,10.172.217.34,lnxsdcc1.oak.sap.corp'
os.environ['no_proxy'] = 'sap.corp,localhost,127.0.0.1,10.172.217.34,lnxsdcc1.oak.sap.corp'
os.environ['HTTPS_PROXY'] = 'http://proxy.oak.sap.corp:8080'
os.environ['HTTP_PROXY'] = 'http://proxy.oak.sap.corp:8080'

def redis_con():
    #redis on lnxsdcc1.oak.sap.corp
    pool = redis.ConnectionPool(host='lnxsdcc1.sjc.sap.corp', port=6379, db=3)
    # r = redis.Redis(connection_pool=pool)
    return pool

def sys_cmd(cmd):
    ret=subprocess.call(cmd,shell=True,stdout=open('/dev/null','w'),stderr=subprocess.STDOUT)
    return ret

def gen_tcf_list(testset_file):
    testset_content_list=open(testset_file).readlines()
    #print testset_content_list
    return_tcf_list=[]
    for a_tcf in testset_content_list:
        #print a_tcf
        if re.match("#.*",a_tcf) or re.match("\s*\n",a_tcf) or a_tcf.find("{")==-1:
            continue
        else:
            #use short path
            tcf_name=a_tcf.split("/")[-1].split("{")[0]
            #use long path
            tcf_name=a_tcf.split("{")[0]
            tcf_no=re.split("{|}",a_tcf)[1].split(",")
            cur_tcf_no_list=[]
            for a_number in tcf_no:
                if a_number.count("-"):
                        cur_begin_no=a_number.split("-")[0]
                        cur_end_no=a_number.split("-")[-1]
                        cur_tcf_no_list.extend(range(int(cur_begin_no),int(cur_end_no)+1))
                else:
                    #print "a_number %s"%(a_number)
                        cur_tcf_no_list.append(a_number)
        cur_tcf_list=map(lambda x:tcf_name+"{"+str(x)+"}",cur_tcf_no_list)
        return_tcf_list.append(cur_tcf_list)
    return return_tcf_list
                

#print time.localtime()
def log_redis(workdir,**kw):
    r = redis.Redis(connection_pool=pool)
    hkey=re.split("_SMP|_SDC",workdir)[0]
    r.zadd(main_key,hkey,0)

    testset_file=workdir+workdir.split("__")[0].split("/")[-1]
    #print testset_file
    tcf_list=[]
    for a_list in gen_tcf_list(testset_file):
        tcf_list.extend(a_list)
    #tcf_list=gen_tcf_list(testset_file)[0]
    map(lambda x:r.hmset(hkey,{"ts_status":"init",x:"init"}),tcf_list)
    #pdb.set_trace()
    #print tcf_list
    if kw.has_key("journal"):
        journal_file=kw["journal"]
        if os.path.exists(journal_file):
            pass
        else:
            print "[FAIL] jounal file %s does not exists!"%(journal_file)
            sys.exit(1)
    elif kw.has_key("result_dir"):
        result_dir=kw["result_dir"]
        if os.path.exists(result_dir):
            journal_file=result_dir+"journal.exec*"
        else:
            print "[FAIL] result dir %s does not exists!"%(result_dir)
            sys.exit(1)
    else:
        journal_file=workdir+"/"+"journal"
        if os.path.exists(journal_file):
            r.hmset(hkey,{"ts_status":"running"})
        else:
            journal_file=workdir+"result."+a_sub_workdir.split("__")[0]+"/"+"journal.exec*"
        # print "[FAIL] jounal file or result dir is not specified!"
        # sys.exit(1)
    # print journal_file
    for a_status in ["PASS","FAIL","UNTESTED","UNRESOLVED"]:
        grep_cmd="grep %s %s | grep tcf"%(a_status,journal_file)
        if subprocess.call(grep_cmd,shell=True,stdout=open('/dev/null','w'),stderr=subprocess.STDOUT):
            pass
        else:
            match_content=subprocess.check_output(grep_cmd,shell=True)
            for a_match in match_content.split("\n"):
                if a_match:
                    cur_match=a_match.split("|")[-1]
                    #print "cur_match: %s"%(cur_match)
                    cur_tcf_name=cur_match.split(":")[0]
                    cur_tcf_status=cur_match.split(":")[1].split()[0].strip()
                    r.hmset(hkey,{cur_tcf_name:cur_tcf_status})
                else:
                    pass

def gen_report(workdir,*testset,**style):
    r = redis.Redis(connection_pool=pool)
    if style.has_key("json"):
        return_value=[]
    else:
        return_value=""
    if testset:
        testset=main_key+"/"+testset[0]+"__*"
        testset_list=r.keys(testset)
    else:
        testset_list=r.zrevrange(main_key,0,-1)
    #print "testset_list=%s"%(testset_list)
    for a_testset in testset_list:
        if a_testset.endswith("/"):
            testset_name=a_testset.split("/")[-2] 
        else:
            testset_name=a_testset.split("/")[-1] 
        cur_tcf_list=r.hkeys(a_testset)
        pass_tcf_list=[]
        fail_tcf_list=[]
        unres_tcf_list=[]
        untest_tcf_list=[]
        notrun_tcf_list=[]
        cur_redis_record=r.hgetall(a_testset)
        for a_tcf in cur_tcf_list:
            if a_tcf=="ts_status":
                cur_ts_status=cur_redis_record[a_tcf]
            else:
                cur_tcf_status=cur_redis_record[a_tcf]
                if cur_tcf_status=="PASS" or cur_tcf_status=="Ok":
                    pass_tcf_list.append(a_tcf)
                elif cur_tcf_status=="FAIL" or cur_tcf_status=="ERROR":
                    fail_tcf_list.append(a_tcf)
                elif cur_tcf_status=="UNRESOLVED":
                    unres_tcf_list.append(a_tcf)
                elif cur_tcf_status=="UNTESTED":
                    untest_tcf_list.append(a_tcf)
                else:
                    notrun_tcf_list.append(a_tcf)
        if style.has_key("json"):
            cur_dict={}
            cur_dict["ts_name"]=testset_name.split("__")[0]
            cur_dict["lock_page"]=testset_name.split("__")[1]
            cur_dict["pass_test_count"]=len(pass_tcf_list)+len(untest_tcf_list)
            cur_dict["fail_test_count"]=len(fail_tcf_list)+len(unres_tcf_list)
            cur_dict["not_run_test_count"]=len(notrun_tcf_list)
            return_value.append(cur_dict)
        else:
            # pdb.set_trace()
            cur_report="Testset:%-40s    PASS:%-5d FAIL:%-5d UNRESOLVED:%-5d UNTESTED:%-5d NOT_RUN:%-5d\n"%(testset_name,len(pass_tcf_list),len(fail_tcf_list),len(unres_tcf_list),len(untest_tcf_list),len(notrun_tcf_list))
            return_value=return_value+cur_report
    return return_value

def gen_rerun(workdir,testset):
    #pdb.set_trace()
    r = redis.Redis(connection_pool=pool)
    try:
        hkey=r.keys(main_key+"/"+testset+"__*")[0]
    except:
        print "[FAIL] %s: no log info found!"%(testset)
    cur_tcf_list=r.hkeys(hkey)
    tcf_list=[]
    for a_tcf in cur_tcf_list:
        if a_tcf=="ts_status":
            pass
        else:
            tcf_list.append(a_tcf)
            cur_tcf_status=r.hget(hkey,a_tcf)
            if cur_tcf_status=="PASS" or cur_tcf_status=="UNTESTED":
                tcf_list.remove(a_tcf)
    rerun_ts="\n".join(tcf_list)
    return rerun_ts

if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument("-log",action="store_true",help="log the result only")
    parser.add_argument("-report",action="store_true",help="generate the report")
    parser.add_argument("-gen_rerun_ts",action="store_true",help="generate the rerun testset")
    parser.add_argument("-b",help="testset execution base dir")
    parser.add_argument("-a",action="store_true",help="log or report all")
    parser.add_argument("-json",action="store_true",help="output json format")
    parser.add_argument("-t",help="testset name")
    parser.add_argument("-j",help="journal file path")
    parser.add_argument("-r",help="grid result.testset dir")
    args=parser.parse_args()
    
    workdir=args.b
    testset=args.t
    journal=args.j
    result_dir=args.r
    
    #sub_workdir_list=subprocess.check_output("ls "+workdir,shell=True).split("\n")
    #print sub_workdir_list
    if os.path.exists(workdir):
        pass
    else:
        print "%s does not exist!"%(workdir)
        sys.exit(1)
    # make sure workdir end with /
    pdb.set_trace()
    workdir=os.path.abspath(workdir)+"/"
    pool=redis_con()
    if workdir.count("func.lam.demo") and workdir.count("__"):
        main_key="/".join(workdir.split("/")[0:-2])
        is_grid=1
    else:
        main_key="/".join(workdir.split("/")[0:-1])
        is_grid=0
    #print "main key "+main_key
    # hkey=re.split("_SMP|_SDC",workdir)[0]

    if args.log:
        try:
            if args.j:
                log_redis(workdir,journal=journal)
            elif args.r:
                log_redis(workdir,result_dir=result_dir)
            elif args.a:
                sub_workdir_list=subprocess.check_output("ls "+workdir,shell=True).split("\n")
                for a_sub_workdir in sub_workdir_list:
                    if a_sub_workdir: 
                        cur_dir=workdir+a_sub_workdir+"/"
                        log_redis(cur_dir) 
            print "[SUC] log successful!"
        except:
            print "[FAIL] log failed!"
    elif args.report:
        if testset:
            print gen_report(workdir,testset)    
        elif args.a:
            if args.json:
                print gen_report(workdir,json=1)
            else:
                print gen_report(workdir) 
        else:
            pass
    elif args.gen_rerun_ts:
        print gen_rerun(workdir,testset)
    else:
        pass
    
